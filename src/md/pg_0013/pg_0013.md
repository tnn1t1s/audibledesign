In contrast, the role of computer instrument builder is somewhat different. Information Technology allows us to build sound-processing tools of immense generality and flexibility (though one might not guess this fact by surveying the musical hardware on sale in high street shops). Much more responsibility is therefore placed on the composer to choose an appropriate (set of) configuration(s) for a particular purpose. The "instrument" is no longer a definable (if subtle) closed universe but a groundswell of possibilities out of which the sonic composer must delimit some aesthetically valid universe. Without some kind of intuitive understanding of the universe of sounds, the problem of choice is insurmountable (unless one replaces it entirely by non- choice strategies, dice-throwing procedures etc).

REAL TIME OR NOT REAL TIME ? - THAT IS THE QUESTION

As computers become faster and faster, and more and more powerful, there is a clamour among musicians working in the medium for "real-time" system, i.e. systems on which we hear the results of our decisions as we take them. A traditional musical instrument is a "real-time system". When we bow a note on a violin, we immediately hear a sound being produced which is the result of our decision to use a particular finger position and bow pressure and which responds immediately to our subtle manual articulation of these. Success in performance also depends on a foreknowledge of what our actions will precipitate. Hence the rationale for having real-time systems seems quite clear in the sphere of musical performance. To develop new, or extended musical performance instruments (including real-time-controllable sound processing devices) we need real-time processing of sounds.

Composition on the other hand would seem, at first glance, to be an intrinsically non-real-time process in which considered and explicit choices are made and used to prepare a musical text (a score), or (in the studio) to put together a work, sound-by-sound, onto a recording medium out of real time. As this book is primarily about composition, we must ask what bearing the development of real-time processing has on compositional practice apart from speeding up some of the more mundane tasks involved.

Although the three traditional roles performer-improviser, instrument-builder and composer are being blurred by the new technological developments, they provide useful poles around which we may assess the value of what we are doing.

I would suggest that there are two conflicting paradigms competing for the attention of the sonic composer. The first is an instrumental paradigm, where the composer provides electronic extensions to a traditional instrumental performance. This approach is intrinsically "real time". The advantages of this paradigm are those of "liveness" (the theatre versus the cinema, the work is recreated 'before your very eyes') and of mutability dependent on each performer's reinterpretation of the work. This approach fits well into a traditional musical way of thinking.

It's disadvantages are not perhaps immediately obvious. But the composer who specifies a network of electronic processing devices around a traditional instrumental performance must recognise that he/she is in fact creating a new and different instrument for the instrumentalist (or instrumentalist-"technician" duo) to play and is partly adopting the role of an instrument builder with its own very different responsibilities. In the neomanic cultural atmosphere of the late Twentieth Century, the temptation for anyone labelled "composer" is to build a new electronic extension for every piece, to establish
<page>7</page>
